# ë©€í‹° GPU ë²„ì „ ì„¤ì¹˜ ë° ì—…ê·¸ë ˆì´ë“œ ê°€ì´ë“œ

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ìƒˆë¡œ ì„¤ì¹˜í•˜ëŠ” ê²½ìš°

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/Jolrin-Saram/auto_label_trainer.git
cd auto_label_trainer

# 2. ë©€í‹° GPU ê°œì„  íŒŒì¼ë¡œ êµì²´
# (ì´ í´ë”ì˜ íŒŒì¼ë“¤ì„ ë³µì‚¬)

# 3. ê°€ìƒ í™˜ê²½ ì„¤ì •
install.bat

# 4. í”„ë¡œê·¸ë¨ ì‹¤í–‰
START_TRAINER.bat
```

### ê¸°ì¡´ ë²„ì „ ì—…ê·¸ë ˆì´ë“œ

í˜„ì¬ GitHub ì €ì¥ì†Œì˜ íŒŒì¼ì„ ì•„ë˜ ê°œì„ ëœ íŒŒì¼ë¡œ êµì²´í•˜ì„¸ìš”:

#### êµì²´í•  íŒŒì¼ (í•„ìˆ˜)

1. **process_and_train.py**
   - ë©€í‹° GPU í•™ìŠµ ì§€ì› ì¶”ê°€
   - Device string parsing
   - DDP ìë™ í™œì„±í™”

2. **auto_labeler.py**
   - GPU ì§€ì • ê¸°ëŠ¥ ì¶”ê°€
   - ë” ë§ì€ ì´ë¯¸ì§€ í¬ë§· ì§€ì›

3. **run_training_ui.py**
   - GPU ì„ íƒ ë“œë¡­ë‹¤ìš´ UI
   - ìë™ GPU ê°ì§€
   - ì„¤ì • ì €ì¥/ë¡œë“œ ê°œì„ 

#### ì¶”ê°€ íŒŒì¼ (ê¶Œì¥)

4. **README_MULTIGPU.md** - ë©€í‹° GPU ì‚¬ìš© ê°€ì´ë“œ
5. **MULTIGPU_UPGRADE_SUMMARY.md** - ê°œì„ ì‚¬í•­ ìš”ì•½
6. **test_multigpu.py** - ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
7. **INSTALLATION_GUIDE.md** - ì´ íŒŒì¼

---

## ğŸ“‹ ìƒì„¸ ì—…ê·¸ë ˆì´ë“œ ì ˆì°¨

### Step 1: ë°±ì—…

```bash
# ê¸°ì¡´ íŒŒì¼ ë°±ì—…
cp process_and_train.py process_and_train.py.backup
cp auto_labeler.py auto_labeler.py.backup
cp run_training_ui.py run_training_ui.py.backup
```

### Step 2: íŒŒì¼ êµì²´

```bash
# ê°œì„ ëœ íŒŒì¼ë¡œ êµì²´
# Windows
copy /Y process_and_train_multigpu.py process_and_train.py
copy /Y auto_labeler_multigpu.py auto_labeler.py
copy /Y run_training_ui.py run_training_ui.py

# Linux/Mac
cp -f process_and_train_multigpu.py process_and_train.py
cp -f auto_labeler_multigpu.py auto_labeler.py
```

### Step 3: í…ŒìŠ¤íŠ¸

```bash
# GPU ê°ì§€ í…ŒìŠ¤íŠ¸
python test_multigpu.py

# í”„ë¡œê·¸ë¨ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
python run_training_ui.py
```

### Step 4: ì„¤ì • í™•ì¸

í”„ë¡œê·¸ë¨ ì‹¤í–‰ í›„:
1. "Training" íƒ­ ì—´ê¸°
2. "Device" ë“œë¡­ë‹¤ìš´ í™•ì¸
3. GPU ëª©ë¡ì´ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸

---

## ğŸ”§ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ í™•ì¸

### CUDA ì„¤ì¹˜ í™•ì¸

```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# PyTorch CUDA ì§€ì› í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"
python -c "import torch; print(torch.cuda.device_count())"
```

ì˜ˆìƒ ì¶œë ¥:
```
True
4
```

### í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸

```bash
pip list | grep -E "torch|ultralytics"
```

ì˜ˆìƒ ì¶œë ¥:
```
torch              2.5.1+cu121
torchaudio         2.5.1+cu121
torchvision        0.20.1+cu121
ultralytics        8.3.204
```

---

## ğŸ¯ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### UI í…ŒìŠ¤íŠ¸
- [ ] í”„ë¡œê·¸ë¨ì´ ì •ìƒ ì‹¤í–‰ë˜ëŠ”ê°€?
- [ ] GPU ê°œìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ëŠ”ê°€?
- [ ] Device ë“œë¡­ë‹¤ìš´ì— ì˜µì…˜ì´ ìˆëŠ”ê°€?
  - [ ] "Auto (All X GPUs)"
  - [ ] "GPU 0: [ëª¨ë¸ëª…]"
  - [ ] "GPU 1: [ëª¨ë¸ëª…]"
  - [ ] "Custom..."

### í•™ìŠµ í…ŒìŠ¤íŠ¸ (ê°„ë‹¨)
- [ ] ì†Œê·œëª¨ ë°ì´í„°ì…‹ ì¤€ë¹„ (ì´ë¯¸ì§€ 10ì¥)
- [ ] Device: "Auto" ì„ íƒ
- [ ] Epochs: 3
- [ ] Batch Size: 8
- [ ] Start Training í´ë¦­
- [ ] ë¡œê·¸ì— "MULTI-GPU TRAINING ENABLED" í‘œì‹œ

### Auto-Labeling í…ŒìŠ¤íŠ¸
- [ ] ëª¨ë¸ íŒŒì¼ (.pt) ì„ íƒ
- [ ] ì´ë¯¸ì§€ í´ë” ì„ íƒ
- [ ] Start Auto-Labeling í´ë¦­
- [ ] Progress Bar ë™ì‘ í™•ì¸
- [ ] ë¼ë²¨ íŒŒì¼ (.txt) ìƒì„± í™•ì¸

---

## ğŸ› ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: "No GPU detected"

**ì¦ìƒ:**
```
Device ë“œë¡­ë‹¤ìš´ì— "CPU (No GPU detected)" ë§Œ í‘œì‹œ
```

**í•´ê²°ì±…:**
```bash
# NVIDIA ë“œë¼ì´ë²„ ì¬ì„¤ì¹˜
# https://www.nvidia.com/Download/index.aspx

# PyTorch CUDA ë²„ì „ ì¬ì„¤ì¹˜
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### ë¬¸ì œ 2: "DDP ì´ˆê¸°í™” ì‹¤íŒ¨"

**ì¦ìƒ:**
```
RuntimeError: Failed to initialize distributed backend
```

**í•´ê²°ì±…:**
1. ë°©í™”ë²½ì—ì„œ Python í—ˆìš©
2. ë‹¨ì¼ GPUë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸
3. ê°€ìƒ í™˜ê²½ ì¬ìƒì„±

### ë¬¸ì œ 3: "CUDA Out of Memory"

**ì¦ìƒ:**
```
RuntimeError: CUDA out of memory
```

**í•´ê²°ì±…:**
```
ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°:
64 â†’ 32 â†’ 16 â†’ 8

ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸:
yolov8x â†’ yolov8l â†’ yolov8m
```

### ë¬¸ì œ 4: "ImportError: cannot import parse_device_string"

**ì¦ìƒ:**
```
test_multigpu.py ì‹¤í–‰ ì‹œ import ì˜¤ë¥˜
```

**í•´ê²°ì±…:**
```bash
# process_and_train.pyê°€ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸
ls process_and_train.py

# íŒŒì¼ì´ ê°œì„  ë²„ì „ì¸ì§€ í™•ì¸ (parse_device_string í•¨ìˆ˜ ìˆì–´ì•¼ í•¨)
grep "def parse_device_string" process_and_train.py
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë°©ë²•

### ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

```bash
# 1 GPU í…ŒìŠ¤íŠ¸
Device: "GPU 0"
Batch: 16
Epochs: 10

# 4 GPU í…ŒìŠ¤íŠ¸
Device: "Auto (All 4 GPUs)"
Batch: 64
Epochs: 10

# ì‹œê°„ ë¹„êµ
# ë¡œê·¸ì—ì„œ "Epoch X/10" ì‹œê°„ ì¸¡ì •
```

### ì˜ˆìƒ ê²°ê³¼

| GPU | Batch | Epoch ì‹œê°„ | ì†ë„ |
|-----|-------|-----------|------|
| 1   | 16    | 10ë¶„      | 1.0x |
| 4   | 64    | 3ë¶„       | 3.3x |

---

## ğŸ”„ ë¡¤ë°± (ì´ì „ ë²„ì „ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°)

ë¬¸ì œ ë°œìƒ ì‹œ:

```bash
# ë°±ì—… íŒŒì¼ë¡œ ë³µì›
cp process_and_train.py.backup process_and_train.py
cp auto_labeler.py.backup auto_labeler.py
cp run_training_ui.py.backup run_training_ui.py

# ë˜ëŠ” GitHubì—ì„œ ë‹¤ì‹œ ë°›ê¸°
git clone https://github.com/Jolrin-Saram/auto_label_trainer.git original_version
```

---

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ í•´ê²°ë˜ì§€ ì•Šìœ¼ë©´:

1. **GitHub Issues**: https://github.com/Jolrin-Saram/auto_label_trainer/issues
2. **ë¡œê·¸ íŒŒì¼ ì²¨ë¶€**: `log_YYYYMMDD_HHMMSS.txt`
3. **ì‹œìŠ¤í…œ ì •ë³´ ì œê³µ**:
   ```bash
   nvidia-smi
   python --version
   pip list | grep torch
   ```

---

## âœ… ì„¤ì¹˜ ì™„ë£Œ í™•ì¸

ëª¨ë“  ê²ƒì´ ì •ìƒì´ë©´:

```
âœ… GPUê°€ ê°ì§€ë¨
âœ… Device ë“œë¡­ë‹¤ìš´ì— GPU ëª©ë¡ í‘œì‹œ
âœ… í…ŒìŠ¤íŠ¸ í•™ìŠµ ì„±ê³µ
âœ… ë¡œê·¸ì— "MULTI-GPU TRAINING ENABLED" í‘œì‹œ
âœ… Auto-Labeling ì‘ë™
```

**ì¶•í•˜í•©ë‹ˆë‹¤! ë©€í‹° GPU í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ!** ğŸ‰

---

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

1. [README_MULTIGPU.md](README_MULTIGPU.md) - ì‚¬ìš© ê°€ì´ë“œ
2. [MULTIGPU_UPGRADE_SUMMARY.md](MULTIGPU_UPGRADE_SUMMARY.md) - ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­
3. ë³¸ê²© í•™ìŠµ ì‹œì‘!
